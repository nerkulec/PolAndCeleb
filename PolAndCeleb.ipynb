{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbaseconda2634e93ee2bc4598b5ba14484a9f8689",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "31534it [00:00, 55982.40it/s]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from V import V, glove\n",
    "\n",
    "glove_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(t):\n",
    "    t = re.sub(r'[^\\x00-\\x7F]+','', t)\n",
    "    t = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' <url> ', t)\n",
    "    t = re.sub(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)', ' <handle> ', t)\n",
    "    t = re.sub(r'(#|\\.|…|-|\\?|!|:|;|%|_|\\\"|\\'|&|“|’|”|\\(|\\)|\\\\|,|/|\\*)', ' ', t)\n",
    "    t = re.sub(r'\\d+', ' <number> ', t)\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    t = t.lower()\n",
    "    if(len(t)>1):\n",
    "        if t[0] == ' ':\n",
    "            t = t[1:]\n",
    "        if t[-1] != ' ':\n",
    "            t = t + ' '\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.csv') as f:\n",
    "    df = pd.read_csv(f)\n",
    "df = df.drop('handle', axis=1)\n",
    "df.set_index('Unnamed: 0', inplace=True)\n",
    "df.index.name = 'id'\n",
    "df['sanitized_text'] = df.text.map(sanitize)\n",
    "df = df.drop('text', axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test.csv') as f:\n",
    "#     test_df = pd.read_csv(f)\n",
    "# test_df['sanitized_text'] = test_df.text.map(sanitize)\n",
    "# pad = \"<pad> \"*4\n",
    "# with open('corpus.txt', 'w') as f:\n",
    "#     for tweet in df.sanitized_text:\n",
    "#         f.write(tweet+pad)\n",
    "#     for tweet in test_df.sanitized_text:\n",
    "#         f.write(tweet+pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>sanitized_text</th>\n      <th>one_hot</th>\n      <th>vectors</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>biz&amp;tech</td>\n      <td>the case for learned index structures replacin...</td>\n      <td>[1, 0, 0, 0]</td>\n      <td>[[0.367821, 0.304186, -0.609452, 1.882143, 0.9...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>biz&amp;tech</td>\n      <td>&lt;handle&gt; lock you in a black box with a window...</td>\n      <td>[1, 0, 0, 0]</td>\n      <td>[[1.287763, 0.304906, -0.47771, 1.626356, 1.01...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>biz&amp;tech</td>\n      <td>what policy outcomes are you aiming to achieve...</td>\n      <td>[1, 0, 0, 0]</td>\n      <td>[[0.96376, -0.303895, -0.180347, 1.166647, 0.1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>biz&amp;tech</td>\n      <td>machine learning for systems and systems for m...</td>\n      <td>[1, 0, 0, 0]</td>\n      <td>[[-0.039726, -0.581507, -0.171636, 1.631949, 0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>biz&amp;tech</td>\n      <td>from the number of talks &lt;handle&gt; given this w...</td>\n      <td>[1, 0, 0, 0]</td>\n      <td>[[0.94299, 0.327011, 0.79898, 0.678095, 1.0002...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      target                                     sanitized_text       one_hot  \\\nid                                                                              \n0   biz&tech  the case for learned index structures replacin...  [1, 0, 0, 0]   \n1   biz&tech  <handle> lock you in a black box with a window...  [1, 0, 0, 0]   \n2   biz&tech  what policy outcomes are you aiming to achieve...  [1, 0, 0, 0]   \n3   biz&tech  machine learning for systems and systems for m...  [1, 0, 0, 0]   \n4   biz&tech  from the number of talks <handle> given this w...  [1, 0, 0, 0]   \n\n                                              vectors  \nid                                                     \n0   [[0.367821, 0.304186, -0.609452, 1.882143, 0.9...  \n1   [[1.287763, 0.304906, -0.47771, 1.626356, 1.01...  \n2   [[0.96376, -0.303895, -0.180347, 1.166647, 0.1...  \n3   [[-0.039726, -0.581507, -0.171636, 1.631949, 0...  \n4   [[0.94299, 0.327011, 0.79898, 0.678095, 1.0002...  "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_all = 0\n",
    "num_bad = 0\n",
    "bad_words = []\n",
    "\n",
    "def get_vector(word):\n",
    "    global num_all, num_bad, bad_words\n",
    "    num_all += 1\n",
    "    try:\n",
    "        return glove[word]\n",
    "    except:\n",
    "        num_bad += 1\n",
    "        bad_words.append(word)\n",
    "        return None\n",
    "\n",
    "def get_vectors(text):\n",
    "    words = text.split()\n",
    "    vectors = np.zeros((20, glove_dim))\n",
    "    missed = 0\n",
    "    for i, word in enumerate(words):\n",
    "        vector = get_vector(word)\n",
    "        if vector is not None:\n",
    "            try:\n",
    "                vectors[i-missed] = vector\n",
    "            except:\n",
    "                missed += 1\n",
    "    return vectors\n",
    "\n",
    "target_dict = {\n",
    "    'biz&tech': np.array([1,0,0,0]),\n",
    "    'celebrity': np.array([0,1,0,0]),\n",
    "    'internetplatform': np.array([0,0,1,0]),\n",
    "    'politician': np.array([0,0,0,1])\n",
    "}\n",
    "\n",
    "name_from_number = ['biz&tech', 'celebrity', 'internetplatform', 'politician']\n",
    "\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: 0.14,\n",
    "    2: 0.533,\n",
    "    3: 0.42\n",
    "}\n",
    "\n",
    "def one_hot(target):\n",
    "    return target_dict[target]\n",
    "\n",
    "\n",
    "df['one_hot'] = df.target.map(one_hot)\n",
    "df['vectors'] = df.sanitized_text.map(get_vectors)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bad/num_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.9)\n",
    "test = df.drop(train.index)\n",
    "tests = {}\n",
    "for num, target in enumerate(target_dict):\n",
    "    tests[target] = test[test.target==target].sample(frac=class_weights[num]*10, replace=True)\n",
    "test = pd.concat([t for t in tests.values()])\n",
    "trainX, trainY = train.vectors.values, train.one_hot.values\n",
    "testX, testY = test.vectors.values, test.one_hot.values\n",
    "trainX = np.array([b for b in trainX])\n",
    "trainY = np.array([b for b in trainY])\n",
    "testX = np.array([b for b in testX])\n",
    "testY = np.array([b for b in testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(None, glove_dim)),\n",
    "    LSTM(48, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(28, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 28823 samples, validate on 10333 samples\nEpoch 1/10\n28823/28823 - 27s - loss: 0.3618 - acc: 0.5361 - val_loss: 0.9291 - val_acc: 0.6365\nEpoch 2/10\n28823/28823 - 24s - loss: 0.2690 - acc: 0.6920 - val_loss: 0.7258 - val_acc: 0.7179\nEpoch 3/10\n28823/28823 - 24s - loss: 0.2302 - acc: 0.7408 - val_loss: 0.7381 - val_acc: 0.7256\nEpoch 4/10\n28823/28823 - 24s - loss: 0.2154 - acc: 0.7591 - val_loss: 0.6114 - val_acc: 0.7727\nEpoch 5/10\n28823/28823 - 24s - loss: 0.2002 - acc: 0.7684 - val_loss: 0.5852 - val_acc: 0.7738\nEpoch 6/10\n28823/28823 - 24s - loss: 0.1876 - acc: 0.7878 - val_loss: 0.5526 - val_acc: 0.7932\nEpoch 7/10\n28823/28823 - 26s - loss: 0.1784 - acc: 0.7931 - val_loss: 0.5417 - val_acc: 0.7932\nEpoch 8/10\n28823/28823 - 26s - loss: 0.1716 - acc: 0.7998 - val_loss: 0.5628 - val_acc: 0.7863\nEpoch 9/10\n28823/28823 - 24s - loss: 0.1655 - acc: 0.8065 - val_loss: 0.5494 - val_acc: 0.8003\nEpoch 10/10\n28823/28823 - 24s - loss: 0.1608 - acc: 0.8080 - val_loss: 0.6228 - val_acc: 0.7940\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fbbf45fb6a0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=10, verbose=2, validation_data=(testX, testY), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model-added-test(90).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "10447/10447 [==============================] - 1s 124us/sample - loss: 0.2525 - acc: 0.9075\n"
    },
    {
     "data": {
      "text/plain": "[0.25254086967309125, 0.9075333]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.csv') as f:\n",
    "    test_df = pd.read_csv(f)\n",
    "test_df.index.name = 'id'\n",
    "test_df['sanitized_text'] = test_df.text.map(sanitize)\n",
    "test_df = test_df.drop('text', axis=1)\n",
    "test_df['vectors'] = test_df.sanitized_text.map(get_vectors)\n",
    "test_df.drop('id', axis=1, inplace=True)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = test_df.vectors.values\n",
    "test_eval = np.array([b for b in test_eval])\n",
    "preds = model.predict_classes(test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['target'] = preds\n",
    "def q(t):\n",
    "    return \"\\\"\"+t+\"\\\"\"\n",
    "test_df['target'] = test_df.target.apply(lambda x: q(name_from_number[x]))\n",
    "test_df.drop('sanitized_text', axis=1, inplace=True)\n",
    "test_df.drop('vectors', axis=1, inplace=True)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('predictions.csv', quoting=3)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}